# Language Mirror â€” Voice-First AI Language Tutor

An immersive, voice-driven language learning app that combines **Google Cloud AI**, **Vertex AI (Gemini)**, and **ElevenLabs** to create natural, conversational practice sessions.

[![Live Demo](https://img.shields.io/badge/demo-live-brightgreen)](https://language-mirror-gemini.vercel.app/)
[![API Status](https://img.shields.io/badge/API-online-blue)](https://language-mirror-api-99706145314.us-central1.run.app/health)

## ğŸ¯ What It Does

Language Mirror lets users **speak naturally** in their target language and instantly receive:

- ğŸ“ **Real-time transcription** (Google Cloud Speech-to-Text)
- âœï¸ **Corrections & explanations** in your native language
- ğŸ­ **Persona-based roleplay responses** (Gemini on Vertex AI)
- ğŸ”Š **Natural voice replies** (ElevenLabs TTS)
- ğŸŒ **Optional translated subtitles** (Google Cloud Translate)

**Example Flow:**
```
You say: "æ˜¨æ—¥ ç§ã¯ è²·ã„ç‰© è¡Œãã¾ã—ãŸ"
         â†“
App transcribes â†’ Corrects â†’ Explains â†’ Responds in character
         â†“
"ãŠãŠã€æ˜¨æ—¥è²·ã„ç‰©è¡Œã£ãŸã‚“ã‚„ã­ï¼ãˆãˆä¹Ÿè¦‹è¦‹ã¤ã‹ã£ãŸã‚“ã‹ï¼Ÿ" (with audio)
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Browser (React) â”‚
â”‚  - Records audio â”‚
â”‚  - Plays replies â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ webm/opus audio
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend (Node + Hono)           â”‚
â”‚  1. Convert â†’ wav (ffmpeg)      â”‚
â”‚  2. STT â†’ text                  â”‚
â”‚  3. Translate â†’ subtitle        â”‚
â”‚  4. Gemini â†’ corrections/reply  â”‚
â”‚  5. ElevenLabs â†’ audio          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
    JSON + mp3 audio
```

### Tech Stack

| Component | Technology |
|-----------|-----------|
| **Frontend** | React + Vite |
| **Backend** | Node.js + Hono (Cloud Run) |
| **Speech-to-Text** | Google Cloud Speech-to-Text |
| **AI Tutor** | Gemini 2.5 Flash (Vertex AI) |
| **Text-to-Speech** | ElevenLabs |
| **Translation** | Google Cloud Translate |
| **Hosting** | Google Cloud Run + Vercel |

---

## âœ¨ Features

- âœ… **Voice Mode** â€” Speak directly to the tutor via `/turn`
- âœ… **Text Mode** â€” Quick testing via `/turn_text`
- âœ… **Persona-Based Roleplay** â€” Practice with different characters (e.g., "Osaka izakaya owner")
- âœ… **Native Language Tips** â€” Get explanations in your language
- âœ… **Conversation History** â€” Maintains context per `conversation_id`
- âœ… **Real-Time Subtitles** â€” Optional translation for clarity

---

## ğŸš€ Quick Start

### Prerequisites

- **Node.js 18+**
- **Google Cloud Project** with enabled APIs:
  - Vertex AI
  - Speech-to-Text
  - Translate (optional)
- **ElevenLabs API Key** ([Get one here](https://elevenlabs.io))
- **ffmpeg** (for audio conversion)

### 1. Clone & Install

```bash
git clone https://github.com/yourusername/language-mirror-gemini.git
cd language-mirror-gemini
npm install
```

### 2. Configure Environment

Create `.env` in the project root:

```bash
# Google Cloud
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_CLOUD_LOCATION=us-central1

# ElevenLabs
ELEVENLABS_API_KEY=your-elevenlabs-key
ELEVENLABS_VOICE_ID=your-voice-id
ELEVENLABS_MODEL_ID=eleven_multilingual_v2

# Server
PORT=3000
```

### 3. Run Backend

```bash
npm run dev
```

**Test health endpoint:**
```bash
curl http://127.0.0.1:3000/health
```

### 4. Run Frontend

```bash
cd web
npm install
npm run dev -- --host
```

**Configure API endpoint** in `web/.env`:
```bash
# Local development
VITE_API_BASE=http://127.0.0.1:3000

# Production
VITE_API_BASE=https://language-mirror-api-99706145314.us-central1.run.app
```

---

## ğŸ“¡ API Reference

### `POST /turn_text`
Text-only mode (no audio input)

**Request:**
```json
{
  "conversation_id": "demo1",
  "target_language": "ja",
  "native_language": "zh-TW",
  "persona": "Osaka izakaya owner",
  "user_text": "æ˜¨æ—¥è²·ã„ç‰©ã«è¡Œãã¾ã—ãŸ"
}
```

**Response:**
```json
{
  "conversation_id": "demo1",
  "corrected_user": "æ˜¨æ—¥ã€è²·ã„ç‰©ã«è¡Œã£ãŸã‚“ã‚„ã­ã€‚",
  "tips_native": "åŠ©è©ã€Œã«ã€è¡¨ç¤ºå‹•ä½œçš„æ–¹å‘...",
  "assistant_reply": "ãŠãŠã€æ˜¨æ—¥è²·ã„ç‰©è¡Œã£ãŸã‚“ã‚„ã­ï¼",
  "follow_up_question": "ä½•è²·ã£ãŸã‚“ï¼Ÿ",
  "assistant_audio_base64": "SUQz..."
}
```

### `POST /turn`
Voice mode with audio input

**Request:** `multipart/form-data`
```
audio: <webm file>
conversation_id: "demo1"
stt_language: "ja-JP"
target_language: "ja"
native_language: "zh-TW"
persona: "Osaka izakaya owner"
subtitle_target: "native" (optional)
```

**Response:** Same as `/turn_text` plus:
```json
{
  "user_text": "æ˜¨æ—¥è²·ã„ç‰©ã«è¡Œãã¾ã—ãŸ",
  "subtitle_native": "æ˜¨å¤©æˆ‘å»è³¼ç‰©äº†",
  ...
}
```

---

## ğŸŒ Deployment

### Backend (Google Cloud Run)

```bash
gcloud run deploy language-mirror-api \
  --source . \
  --allow-unauthenticated \
  --region us-central1 \
  --set-env-vars GOOGLE_CLOUD_PROJECT=your-project-id,ELEVENLABS_API_KEY=your-key
```

### Frontend (Vercel)

1. Import your GitHub repo in Vercel
2. Set **Root Directory** = `web`
3. Add environment variable:
   ```
   VITE_API_BASE=https://language-mirror-api-99706145314.us-central1.run.app
   ```
4. Deploy ğŸš€

---

## ğŸ“ Project Structure

```
language-mirror-gemini/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts              # Main server (Hono)
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ gemini.ts         # Vertex AI integration
â”‚       â”œâ”€â”€ eleven.ts         # ElevenLabs TTS
â”‚       â”œâ”€â”€ speech.ts         # Google STT
â”‚       â””â”€â”€ translate.ts      # Google Translate
â”œâ”€â”€ web/                      # Frontend (React + Vite)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ components/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ Dockerfile                # Cloud Run container
â”œâ”€â”€ package.json
â””â”€â”€ .env.example
```

---

## ğŸ“ Use Cases

- **Language Learning** â€” Practice conversation with AI tutors
- **Pronunciation Practice** â€” Get instant feedback on your speech
- **Roleplay Scenarios** â€” Practice real-world situations (ordering food, shopping, etc.)
- **Grammar Correction** â€” Learn from mistakes with native-language explanations

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details

---

## ğŸ™ Acknowledgments

- **Google Cloud** for Speech-to-Text, Vertex AI, and Translate APIs
- **ElevenLabs** for high-quality multilingual TTS
- **Anthropic** for inspiration from conversational AI patterns

---

## ğŸ“ Support

- **Live Demo**: [language-mirror-gemini.vercel.app](https://language-mirror-gemini.vercel.app/)
- **Issues**: [GitHub Issues](https://github.com/yourusername/language-mirror-gemini/issues)
- **API Health**: [Check Status](https://language-mirror-api-99706145314.us-central1.run.app/health)

---

**Built with â¤ï¸ for language learners worldwide**